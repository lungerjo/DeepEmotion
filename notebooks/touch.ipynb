{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to inspect the touch signals and make them compatible as model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -- 1. Read your data --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    start     end     actor recipient bodypart_actor bodypart_recipient  \\\n",
      "0  281.72  286.20    OLDMAN   FORREST            ARM       BACK ARM LEG   \n",
      "1  285.76  286.20    OLDMAN   FORREST            ARM              CHEST   \n",
      "2  289.72  289.84  MRS_GUMP   FORREST           HAND               HAND   \n",
      "3  290.00  290.92  MRS_GUMP   FORREST           HAND                LEG   \n",
      "4  314.24  316.32  MRS_GUMP   FORREST           HAND               HAND   \n",
      "\n",
      "             label  intensity_of_body_contact valence_actor valence_recipient  \\\n",
      "0  CHANGE_POSITION                          1      POSITIVE          POSITIVE   \n",
      "1              TAP                          0      POSITIVE          POSITIVE   \n",
      "2       BRUSH PAST                          0      POSITIVE          POSITIVE   \n",
      "3     FIX_CLOTHING                          0      POSITIVE          POSITIVE   \n",
      "4       HOLD_HANDS                          0      POSITIVE          POSITIVE   \n",
      "\n",
      "   intention audio_information  \n",
      "0          1         NARRATION  \n",
      "1          1               NaN  \n",
      "2          1               NaN  \n",
      "3          1               NaN  \n",
      "4          1               NaN  \n",
      "   offset  start  end character arousal valence direction emotion oncue offcue\n",
      "0       0    NaN  NaN       NaN     NaN     NaN       NaN    NONE   NaN    NaN\n",
      "1       2    NaN  NaN       NaN     NaN     NaN       NaN    NONE   NaN    NaN\n",
      "2       4    NaN  NaN       NaN     NaN     NaN       NaN    NONE   NaN    NaN\n",
      "3       6    NaN  NaN       NaN     NaN     NaN       NaN    NONE   NaN    NaN\n",
      "4       8    NaN  NaN       NaN     NaN     NaN       NaN    NONE   NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "touch_path = \"/Users/joshualunger/DeepEmotion/data/annotations/src/bodycontact/data/obs4.csv\"\n",
    "emotion_path = \"/Users/joshualunger/DeepEmotion/data/resampled_annotations/av1o6_resampled.tsv\"\n",
    "# Read the CSV file\n",
    "touch_df = pd.read_csv(touch_path)\n",
    "emotion_df = pd.read_csv(emotion_path, sep='\\t') \n",
    "\n",
    "# Print the first few rows\n",
    "print(touch_df.head())\n",
    "print(emotion_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- 2. Extract unique body parts --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABDOMEN', 'ARM', 'BACK', 'BUTTOCKS', 'CHEST', 'FACE', 'FOOT', 'HAND', 'HEAD', 'HIP', 'LAP', 'LEG', 'NAPE', 'NECK', 'SHOULDER']\n",
      "['ABDOMEN_actor', 'ARM_actor', 'BACK_actor', 'BUTTOCKS_actor', 'CHEST_actor', 'FACE_actor', 'FOOT_actor', 'HAND_actor', 'HEAD_actor', 'HIP_actor', 'LAP_actor', 'LEG_actor', 'NAPE_actor', 'NECK_actor', 'SHOULDER_actor']\n",
      "['ABDOMEN_recipient', 'ARM_recipient', 'BACK_recipient', 'BUTTOCKS_recipient', 'CHEST_recipient', 'FACE_recipient', 'FOOT_recipient', 'HAND_recipient', 'HEAD_recipient', 'HIP_recipient', 'LAP_recipient', 'LEG_recipient', 'NAPE_recipient', 'NECK_recipient', 'SHOULDER_recipient']\n"
     ]
    }
   ],
   "source": [
    "# 1. Convert NaN to empty string to avoid errors when splitting\n",
    "touch_df['bodypart_actor'] = touch_df['bodypart_actor'].fillna('')\n",
    "touch_df['bodypart_recipient'] = touch_df['bodypart_recipient'].fillna('')\n",
    "\n",
    "# 2. Split each cell on whitespace, collect into lists\n",
    "actor_bodyparts_lists = touch_df['bodypart_actor'].apply(lambda x: x.split())\n",
    "recipient_bodyparts_lists = touch_df['bodypart_recipient'].apply(lambda x: x.split())\n",
    "\n",
    "# 3. Flatten these lists and find unique body parts\n",
    "all_actor_bps = set(itertools.chain.from_iterable(actor_bodyparts_lists))\n",
    "all_recipient_bps = set(itertools.chain.from_iterable(recipient_bodyparts_lists))\n",
    "\n",
    "all_unique_bodyparts = sorted(all_actor_bps.union(all_recipient_bps))\n",
    "\n",
    "actor_columns = [f\"{bp}_actor\" for bp in all_unique_bodyparts]\n",
    "recipient_columns = [f\"{bp}_recipient\" for bp in all_unique_bodyparts]\n",
    "\n",
    "print(all_unique_bodyparts)\n",
    "print(actor_columns)\n",
    "print(recipient_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- 3. Prepare an empty result list --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_rows = []\n",
    "\n",
    "for i, emotion_row in emotion_df.iterrows():\n",
    "    current_offset = emotion_row['offset']\n",
    "\n",
    "    # -- Find all touch events active at this offset\n",
    "    active_touches = touch_df[\n",
    "        (touch_df['start'] <= current_offset) &\n",
    "        (touch_df['end'] >= current_offset)\n",
    "    ]\n",
    "\n",
    "    # -- Initialize body part one-hot dict for both actor & recipient\n",
    "    bodypart_encoding = {col: 0 for col in actor_columns + recipient_columns}\n",
    "\n",
    "    # -- For each active touch event, parse multiple body parts\n",
    "    for _, touch_row in active_touches.iterrows():\n",
    "        # Split the actor's bodypart string into a list\n",
    "        actor_bps = touch_row['bodypart_actor'].split()\n",
    "        # Split the recipient's bodypart string into a list\n",
    "        recipient_bps = touch_row['bodypart_recipient'].split()\n",
    "\n",
    "        # Mark the actor body parts as 1\n",
    "        for bp in actor_bps:\n",
    "            col_name = f\"{bp}_actor\"\n",
    "            if col_name in bodypart_encoding:\n",
    "                bodypart_encoding[col_name] = 1\n",
    "\n",
    "        # Mark the recipient body parts as 1\n",
    "        for bp in recipient_bps:\n",
    "            col_name = f\"{bp}_recipient\"\n",
    "            if col_name in bodypart_encoding:\n",
    "                bodypart_encoding[col_name] = 1\n",
    "\n",
    "    # -- Combine the emotion data with the one-hot-encoded body parts\n",
    "    aligned_rows.append({\n",
    "        'offset':    current_offset,\n",
    "        'start':     emotion_row.get('start'),\n",
    "        'end':       emotion_row.get('end'),\n",
    "        'character': emotion_row.get('character'),\n",
    "        'arousal':   emotion_row.get('arousal'),\n",
    "        'valence':   emotion_row.get('valence'),\n",
    "        'direction': emotion_row.get('direction'),\n",
    "        'emotion':   emotion_row.get('emotion'),\n",
    "        'oncue':     emotion_row.get('oncue'),\n",
    "        'offcue':    emotion_row.get('offcue'),\n",
    "        **bodypart_encoding\n",
    "    })\n",
    "\n",
    "# -- Convert to DataFrame\n",
    "emotion_df = pd.DataFrame(aligned_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- 4. Convert to DataFrame --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['offset', 'start', 'end', 'character', 'arousal', 'valence', 'direction', 'emotion', 'oncue', 'offcue', 'ABDOMEN_actor', 'ARM_actor', 'BACK_actor', 'BUTTOCKS_actor', 'CHEST_actor', 'FACE_actor', 'FOOT_actor', 'HAND_actor', 'HEAD_actor', 'HIP_actor', 'LAP_actor', 'LEG_actor', 'NAPE_actor', 'NECK_actor', 'SHOULDER_actor', 'ABDOMEN_recipient', 'ARM_recipient', 'BACK_recipient', 'BUTTOCKS_recipient', 'CHEST_recipient', 'FACE_recipient', 'FOOT_recipient', 'HAND_recipient', 'HEAD_recipient', 'HIP_recipient', 'LAP_recipient', 'LEG_recipient', 'NAPE_recipient', 'NECK_recipient', 'SHOULDER_recipient']\n",
      "   offset  start  end character arousal valence direction emotion oncue  \\\n",
      "0       0    NaN  NaN       NaN     NaN     NaN       NaN    NONE   NaN   \n",
      "1       2    NaN  NaN       NaN     NaN     NaN       NaN    NONE   NaN   \n",
      "2       4    NaN  NaN       NaN     NaN     NaN       NaN    NONE   NaN   \n",
      "3       6    NaN  NaN       NaN     NaN     NaN       NaN    NONE   NaN   \n",
      "4       8    NaN  NaN       NaN     NaN     NaN       NaN    NONE   NaN   \n",
      "\n",
      "  offcue  ...  FACE_recipient  FOOT_recipient  HAND_recipient  HEAD_recipient  \\\n",
      "0    NaN  ...               0               0               0               0   \n",
      "1    NaN  ...               0               0               0               0   \n",
      "2    NaN  ...               0               0               0               0   \n",
      "3    NaN  ...               0               0               0               0   \n",
      "4    NaN  ...               0               0               0               0   \n",
      "\n",
      "   HIP_recipient  LAP_recipient  LEG_recipient  NAPE_recipient  \\\n",
      "0              0              0              0               0   \n",
      "1              0              0              0               0   \n",
      "2              0              0              0               0   \n",
      "3              0              0              0               0   \n",
      "4              0              0              0               0   \n",
      "\n",
      "   NECK_recipient  SHOULDER_recipient  \n",
      "0               0                   0  \n",
      "1               0                   0  \n",
      "2               0                   0  \n",
      "3               0                   0  \n",
      "4               0                   0  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "offset: 1538\n",
      "start: nan\n",
      "end: nan\n",
      "character: nan\n",
      "arousal: nan\n",
      "valence: nan\n",
      "direction: nan\n",
      "emotion: NONE\n",
      "oncue: nan\n",
      "offcue: nan\n",
      "ABDOMEN_actor: 0\n",
      "ARM_actor: 1\n",
      "BACK_actor: 1\n",
      "BUTTOCKS_actor: 1\n",
      "CHEST_actor: 0\n",
      "FACE_actor: 0\n",
      "FOOT_actor: 1\n",
      "HAND_actor: 0\n",
      "HEAD_actor: 0\n",
      "HIP_actor: 1\n",
      "LAP_actor: 0\n",
      "LEG_actor: 1\n",
      "NAPE_actor: 1\n",
      "NECK_actor: 0\n",
      "SHOULDER_actor: 1\n",
      "ABDOMEN_recipient: 0\n",
      "ARM_recipient: 1\n",
      "BACK_recipient: 1\n",
      "BUTTOCKS_recipient: 1\n",
      "CHEST_recipient: 0\n",
      "FACE_recipient: 0\n",
      "FOOT_recipient: 1\n",
      "HAND_recipient: 0\n",
      "HEAD_recipient: 0\n",
      "HIP_recipient: 1\n",
      "LAP_recipient: 0\n",
      "LEG_recipient: 1\n",
      "NAPE_recipient: 1\n",
      "NECK_recipient: 0\n",
      "SHOULDER_recipient: 1\n",
      "Number of rows in emotion CSV: 3517\n",
      "Number of rows in touch CSV: 3517\n"
     ]
    }
   ],
   "source": [
    "emotion_df = pd.DataFrame(aligned_rows)\n",
    "\n",
    "# Display results\n",
    "print(list(emotion_df.columns))\n",
    "print(emotion_df.head())\n",
    "row = emotion_df[emotion_df['offset'] == 1538]\n",
    "\n",
    "if row.empty:\n",
    "    print(\"No row found for offset 1538.\")\n",
    "else:\n",
    "    row_dict = row.to_dict(orient=\"records\")[0]  # Convert row to dictionary\n",
    "    for key, value in row_dict.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"Number of rows in emotion CSV: {emotion_df.shape[0]}\")\n",
    "print(f\"Number of rows in touch CSV: {emotion_df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- 5. Export Dataframe --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion DataFrame saved to: /Users/joshualunger/DeepEmotion/data/resampled_annotations/emotions_resampled.tsv\n"
     ]
    }
   ],
   "source": [
    "output_path = \"/Users/joshualunger/DeepEmotion/data/resampled_annotations/emotions_resampled.tsv\"\n",
    "\n",
    "# Export to TSV (preserving tab separator)\n",
    "emotion_df.to_csv(output_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Emotion DataFrame saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepemotion-2tkljnzJ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
