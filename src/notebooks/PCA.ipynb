{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: Quadro M4000\n",
      "{'project_root': '/home/paperspace/DeepEmotion', 'verbose': True, 'wandb': True, 'sys_log': True, 'model': 'CNN', 'CNN': {'c1': 16, 'c2': 32, 'c3': 64, 'k1': 3, 'k2': 3, 'k3': 3, 'pk': 2, 'ps': 2, 'kernel_size': 3, 'stride': 1, 'padding': 1}, 'train': {'epochs': 50, 'batch_size': 20, 'shuffle': True, 'train_ratio': 0.8, 'print_label_frequencies': True}, 'data': {'data_path': '${project_root}/data/raw/derivatives/non-linear_anatomical_alignment', 'zarr_dir_path': '${project_root}/zarr_datasets', 'zarr_path': '${project_root}/zarr_datasets/pool_emotions', 'label_path': '${project_root}/data/updated_annotations/pooled_annotations_structured.tsv', 'sessions': ['01', '02', '03', '04', '05', '06', '07', '08'], 'file_pattern_template': '*_ses-forrestgump_task-forrestgump_rec-dico7Tad2grpbold7TadNL_run-{}_bold.nii.gz', 'subjects': ['sub-01', 'sub-02', 'sub-03', 'sub-04', 'sub-05', 'sub-06', 'sub-07', 'sub-08', 'sub-09', 'sub-11', 'sub-12', 'sub-13', 'sub-14', 'sub-15', 'sub-16', 'sub-17', 'sub-18', 'sub-19', 'sub-20'], 'session_offsets': [0, 902, 1784, 2660, 3636, 4560, 5438, 6522], 'emotion_idx': {'NONE': 0, 'HAPPINESS': 1, 'FEAR': 2, 'SADNESS': 3, 'LOVE': 4, 'ANGER': 5}, 'normalization': False, 'weight_decay': 0, 'learning_rate': 0.0001, 'seed': 42, 'save_model': True, 'load_model': False, 'save_model_path': 'output/models', 'load_model_path': 'None'}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.dataset import get_data_loaders\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra import initialize, compose\n",
    "import torch\n",
    "import os\n",
    "from utils.dataset import get_data_loaders\n",
    "from models.CNN import CNN\n",
    "from models.resnet import ResNet, BasicBlock\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from utils.dataset import get_data_loaders\n",
    "from models.CNN import CNN\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is NOT available. Using CPU.\")\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "with initialize(version_base=None, config_path=\"../src/configs\"):\n",
    "    cfg = compose(config_name=\"base\", overrides=[\"project_root=/home/paperspace/DeepEmotion\"])\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 152 files.\n",
      "Spatial dimensions: (132, 175, 48)\n",
      "Maximum timepoints per file: 542\n",
      "Subjects: ['sub-01' 'sub-02' 'sub-03' 'sub-04' 'sub-05' 'sub-06' 'sub-07' 'sub-08'\n",
      " 'sub-09' 'sub-11' 'sub-12' 'sub-13' 'sub-14' 'sub-15' 'sub-16' 'sub-17'\n",
      " 'sub-18' 'sub-19' 'sub-20']\n",
      "Sessions: ['01' '02' '03' '04' '05' '06' '07' '08']\n",
      "Emotion categories: ['NONE', 'HAPPINESS', 'FEAR', 'SADNESS', 'LOVE', 'ANGER']\n",
      "Total valid labeled timepoints: 15181\n",
      "Cell 2 complete: Loaded the dataset.\n",
      "Number of train batches: 608\n",
      "Shape of one batch of data: torch.Size([20, 132, 175, 48])\n",
      "batch_size: 20\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = get_data_loaders(cfg)\n",
    "\n",
    "num_train_batches = len(train_dataloader)\n",
    "sample_batch = next(iter(train_dataloader))\n",
    "batch_data = sample_batch[\"data_tensor\"]\n",
    "\n",
    "print(f\"Cell 2 complete: Loaded the dataset.\")\n",
    "print(f\"Number of train batches: {num_train_batches}\")\n",
    "print(f\"Shape of one batch of data: {batch_data.shape}\")\n",
    "print(f\"batch_size: {cfg.train.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA projections saved to /home/paperspace/DeepEmotion/src/output/PCA/raw/sub_ALL.csv\n"
     ]
    }
   ],
   "source": [
    "# Invert the label dictionary\n",
    "inverse_emotion_idx = {v: k for k, v in cfg.data.emotion_idx.items()}\n",
    "\n",
    "n_components = 2  # if you're only using 2 now\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Get dataset dimensions\n",
    "sample_batch = next(iter(train_dataloader))[\"data_tensor\"]\n",
    "num_features = sample_batch.shape[1] * sample_batch.shape[2] * sample_batch.shape[3]  # e.g., 132 * 175 * 48\n",
    "\n",
    "W = torch.randn(num_features, n_components, device=device)\n",
    "mean_running = torch.zeros(num_features, device=device)\n",
    "num_samples = 0\n",
    "results = []\n",
    "\n",
    "for batch_idx, batch in enumerate(train_dataloader):\n",
    "    batch_data = batch[\"data_tensor\"].float().to(device, non_blocking=True)\n",
    "    batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "\n",
    "    batch_mean = batch_data.mean(dim=0)\n",
    "    num_samples += batch_data.shape[0]\n",
    "    mean_running = (mean_running * (num_samples - batch_data.shape[0]) \n",
    "                    + batch_data.shape[0] * batch_mean) / num_samples\n",
    "\n",
    "    batch_data -= mean_running\n",
    "\n",
    "    # Power iteration / simple incremental update\n",
    "    temp_projection = batch_data @ W\n",
    "    U, S, Vh = torch.linalg.svd(temp_projection, full_matrices=False)\n",
    "    W = W @ Vh[:n_components].T  # W remains [num_features, 2]\n",
    "\n",
    "    batch_projection = batch_data @ W  # shape [B, 2]\n",
    "\n",
    "    # Retrieve labels\n",
    "    labels = batch[\"label_tensor\"]\n",
    "    \n",
    "    # Convert to CPU for final results\n",
    "    batch_projection_cpu = batch_projection.cpu().numpy()\n",
    "    labels_cpu = labels.cpu().numpy()\n",
    "\n",
    "    # Store PC values plus label name\n",
    "    for i in range(batch_projection_cpu.shape[0]):\n",
    "        pc_values = list(batch_projection_cpu[i])  \n",
    "        label_idx = labels_cpu[i]\n",
    "        label_name = inverse_emotion_idx.get(label_idx, \"UNK\")\n",
    "        pc_values.append(label_name)\n",
    "        results.append(pc_values)\n",
    "\n",
    "# Write to CSV\n",
    "columns = [f\"PC{i+1}\" for i in range(n_components)] + [\"EmotionLabel\"]\n",
    "df = pd.DataFrame(results, columns=columns)\n",
    "csv_path = \"/home/paperspace/DeepEmotion/src/output/PCA/raw/sub_ALL.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"PCA projections saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 152 files.\n",
      "Spatial dimensions: (132, 175, 48)\n",
      "Maximum timepoints per file: 542\n",
      "Subjects: ['sub-01' 'sub-02' 'sub-03' 'sub-04' 'sub-05' 'sub-06' 'sub-07' 'sub-08'\n",
      " 'sub-09' 'sub-11' 'sub-12' 'sub-13' 'sub-14' 'sub-15' 'sub-16' 'sub-17'\n",
      " 'sub-18' 'sub-19' 'sub-20']\n",
      "Sessions: ['01' '02' '03' '04' '05' '06' '07' '08']\n",
      "Emotion categories: ['NONE', 'HAPPINESS', 'FEAR', 'SADNESS', 'LOVE', 'ANGER']\n",
      "Total valid labeled timepoints: 15181\n",
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting IncrementalPCA Epoch 1: 100%|██████████| 608/608 [08:30<00:00,  1.19it/s]\n",
      "Transforming after final epoch: 100%|██████████| 608/608 [08:22<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA to /home/paperspace/DeepEmotion/src/output/PCA/hidden/sub_ALL.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from omegaconf import OmegaConf\n",
    "from utils.dataset import get_data_loaders\n",
    "from models.CNN import CNN\n",
    "\n",
    "# Config variables\n",
    "PROJECT_ROOT = os.path.abspath(\"../\")\n",
    "\n",
    "cfg = OmegaConf.create({\n",
    "    \"project_root\": PROJECT_ROOT,\n",
    "    \"verbose\": True,\n",
    "    \"wandb\": True,\n",
    "    \"sys_log\": True,\n",
    "    \"model\": \"CNN\",\n",
    "    \"CNN\": {\n",
    "        \"c1\": 16, \"c2\": 32, \"c3\": 64, \"k1\": 3, \"k2\": 3, \"k3\": 3,\n",
    "        \"pk\": 2, \"ps\": 2, \"kernel_size\": 3, \"stride\": 1, \"padding\": 1\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"epochs\": 50, \"batch_size\": 20, \"shuffle\": True, \"train_ratio\": 0.8,\n",
    "        \"print_label_frequencies\": True\n",
    "    },\n",
    "    \"data\": {\n",
    "        \"data_path\": f\"{PROJECT_ROOT}/data/raw/derivatives/non-linear_anatomical_alignment\",\n",
    "        \"zarr_dir_path\": f\"{PROJECT_ROOT}/zarr_datasets\",\n",
    "        \"zarr_path\": f\"{PROJECT_ROOT}/zarr_datasets/pool_emotions\",\n",
    "        \"label_path\": f\"{PROJECT_ROOT}/data/updated_annotations/pooled_annotations_structured.tsv\",\n",
    "        \"sessions\": [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\"],\n",
    "        \"file_pattern_template\": \"*_ses-forrestgump_task-forrestgump_rec-dico7Tad2grpbold7TadNL_run-{}_bold.nii.gz\",\n",
    "        \"subjects\": [\"sub-7\"],\n",
    "        \"session_offsets\": [0, 902, 1784, 2660, 3636, 4560, 5438, 6522],\n",
    "        \"emotion_idx\": {\"NONE\": 0, \"HAPPINESS\": 1, \"FEAR\": 2, \"SADNESS\": 3, \"LOVE\": 4, \"ANGER\": 5},\n",
    "        \"normalization\": False,\n",
    "        \"weight_decay\": 0,\n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"seed\": 42,\n",
    "        \"save_model\": True,\n",
    "        \"load_model\": False,\n",
    "        \"save_model_path\": \"output/models\",\n",
    "        \"load_model_path\": f\"{PROJECT_ROOT}/src/output/models/sub_ALL.pth\",\n",
    "        \"output_csv_path\": f\"{PROJECT_ROOT}/src/output/PCA/hidden/sub_ALL.csv\"\n",
    "    }\n",
    "})\n",
    "\n",
    "# Load dataloaders\n",
    "train_dataloader, val_dataloader = get_data_loaders(cfg)\n",
    "\n",
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN(cfg=cfg, output_dim=len(cfg.data.emotion_idx))\n",
    "model.load_state_dict(torch.load(cfg.data.load_model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Get hidden state dimension\n",
    "sample_batch = next(iter(train_dataloader))[\"data_tensor\"].to(device).float()\n",
    "with torch.no_grad():\n",
    "    _, hidden_sample = model(sample_batch[:1], return_hidden=True)\n",
    "hidden_dim = hidden_sample.shape[1]\n",
    "\n",
    "# Invert emotion label map\n",
    "inverse_emotion_idx = {v: k for k, v in cfg.data.emotion_idx.items()}\n",
    "\n",
    "# PCA loop\n",
    "n_components = 2\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "    \n",
    "    ipca = IncrementalPCA(n_components=n_components)\n",
    "\n",
    "    # Fit PCA incrementally\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Fitting IncrementalPCA Epoch {epoch}\"):\n",
    "        data = batch[\"data_tensor\"].float().to(device)\n",
    "        with torch.no_grad():\n",
    "            _, hidden = model(data, return_hidden=True)\n",
    "        ipca.partial_fit(hidden.cpu().numpy())\n",
    "\n",
    "# After final epoch, transform and save\n",
    "all_hidden = []\n",
    "all_labels = []\n",
    "\n",
    "for batch in tqdm(train_dataloader, desc=\"Transforming after final epoch\"):\n",
    "    data = batch[\"data_tensor\"].float().to(device)\n",
    "    labels = batch[\"label_tensor\"]\n",
    "    with torch.no_grad():\n",
    "        _, hidden = model(data, return_hidden=True)\n",
    "    all_hidden.append(hidden.cpu().numpy())\n",
    "    all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "all_hidden = np.concatenate(all_hidden, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "pca_proj = ipca.transform(all_hidden)\n",
    "\n",
    "results = []\n",
    "for row, label_idx in zip(pca_proj, all_labels):\n",
    "    row = list(row)\n",
    "    row.append(inverse_emotion_idx.get(label_idx, \"UNK\"))\n",
    "    results.append(row)\n",
    "\n",
    "df = pd.DataFrame(results, columns=[\"PC1\", \"PC2\", \"EmotionLabel\"])\n",
    "save_dir = os.path.join(cfg.project_root, \"src/output/PCA/hidden\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "csv_path = os.path.join(save_dir, \"sub_ALL.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"Saved PCA to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepemotion-r8YRC923-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
