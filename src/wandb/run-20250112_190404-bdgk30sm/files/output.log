Device: cuda
Loading dataloader...
Zarr Dataset: /home/paperspace/DeepEmotion/src/../dataset.zarr
Dataset contains 16 files.
Spatial dimensions: (132, 175, 48)
Maximum timepoints per file: 542
Subjects: ['sub-01' 'sub-02']
Sessions: ['01' '02' '03' '04' '05' '06' '07' '08']
Emotion categories: ['NONE', 'HAPPINESS', 'FEAR', 'SADNESS', 'LOVE', 'ANGERRAGE', 'CONTEMPT', 'GRATITUDE', 'ADMIRATION', 'COMPASSION', 'PRIDE', 'REMORSE', 'DISAPPOINTMENT', 'HAPPYFOR', 'GLOATING', 'SATISFACTION', 'HOPE', 'HATE', 'RELIEF', 'SHAME', 'GRATIFICATION', 'FEARSCONFIRMED']
Total valid labeled timepoints: 1496
Zarr Path: /home/paperspace/DeepEmotion/src/../dataset.zarr
Loaded Observations: 1496
  0%|                                                                                                                             | 0/120 [00:04<?, ?it/s]
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/paperspace/DeepEmotion/src/train vgg.py", line 67, in main
    output = model(data)
             ^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/DeepEmotion/src/models/vgg.py", line 39, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 725, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/paperspace/.cache/pypoetry/virtualenvs/deepemotion-r8YRC923-py3.12/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 720, in _conv_forward
    return F.conv3d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [64, 1, 3, 3, 3], expected input[1, 10, 132, 175, 48] to have 1 channels, but got 10 channels instead

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
