{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling Touch Annotations\n",
    "#### from https://github.com/psychoinformatics-de/studyforrest-paper-bodycontactannotation/tree/master/data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align annotations into 2 second timesteps, if there are multiple in the same timestep, keep both to be processed later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: /Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/obs5_expanded.tsv\n",
      "Processed and saved: /Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/obs4_expanded.tsv\n",
      "Processed and saved: /Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/obs6_expanded.tsv\n",
      "Processed and saved: /Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/obs7_expanded.tsv\n",
      "Processed and saved: /Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/obs3_expanded.tsv\n",
      "Processed and saved: /Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/obs2_expanded.tsv\n",
      "Processed and saved: /Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/obs1_expanded.tsv\n",
      "{'DAN', 'WOMAN', 'CROWD', 'BUBBA', 'MRS_GUMP', nan, 'OLDMAN', 'OLDWOMAN', 'FORREST', 'MEN', 'BOY', 'CHILDREN', 'JENNY'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "file_paths = glob.glob('/Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/raw/*.csv')\n",
    "\n",
    "all_characters = set([])\n",
    "def expand_to_timesteps(df, max_time):\n",
    "    '''Expand the entire dataframe into 2-second timesteps, creating separate rows for overlapping labels.'''\n",
    "    timesteps = np.arange(0, max_time + 2.0, 2.0)  \n",
    "    expanded_rows = []\n",
    "\n",
    "    for ts in timesteps:\n",
    "        active_rows = df[(df['start'].apply(math.floor) <= ts) & (df['end'].apply(math.floor) >= ts)]\n",
    "\n",
    "        if not active_rows.empty:\n",
    "            for _, row in active_rows.iterrows():\n",
    "                all_characters.update({row['actor']})\n",
    "                all_characters.update({row['recipient']})\n",
    "\n",
    "                expanded_rows.append({\n",
    "                    'timestep': ts,\n",
    "                    'actor': row['actor'],\n",
    "                    'recipient': row['recipient'],\n",
    "                    'bodypart_actor': row['bodypart_actor'],\n",
    "                    'bodypart_recipient': row['bodypart_recipient'],\n",
    "                    'label': row['label'],\n",
    "                    'intensity_of_body_contact': row['intensity_of_body_contact'],\n",
    "                    'valence_actor': row['valence_actor'],\n",
    "                    'valence_recipient': row['valence_recipient'],\n",
    "                    'intention': row['intention'],\n",
    "                    'audio_information': row['audio_information']\n",
    "                })\n",
    "        else:\n",
    "            # No active row for this timestep, fill with NONE\n",
    "            expanded_rows.append({\n",
    "                'timestep': ts,\n",
    "                'actor': None,\n",
    "                'recipient': None,\n",
    "                'bodypart_actor': None,\n",
    "                'bodypart_recipient': None,\n",
    "                'label': 'NONE',\n",
    "                'intensity_of_body_contact': None,\n",
    "                'valence_actor': None,\n",
    "                'valence_recipient': None,\n",
    "                'intention': None,\n",
    "                'audio_information': None\n",
    "            })\n",
    "\n",
    "    return expanded_rows\n",
    "\n",
    "expanded_file_paths = []\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    max_time = df['end'].max()\n",
    "\n",
    "    expanded_data = expand_to_timesteps(df, max_time)\n",
    "\n",
    "    expanded_df = pd.DataFrame(expanded_data)\n",
    "    output_path = file_path.replace('.csv', '_expanded.tsv').replace('/raw', '')\n",
    "    expanded_file_paths.append(output_path)\n",
    "    expanded_df.to_csv(output_path, index=False, sep='\\t')\n",
    "\n",
    "    print(f'Processed and saved: {output_path}')\n",
    "\n",
    "print(all_characters)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved popular vote results to /Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/obs_pop_vote.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "file_paths = glob.glob('/Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/*_expanded.tsv')\n",
    "\n",
    "dataframes = [pd.read_csv(file, sep='\\t') for file in expanded_file_paths]\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "max_ts = combined_df['timestep'].max()\n",
    "timesteps = np.arange(0, max_ts, 2.0)\n",
    "count = 0\n",
    "\n",
    "main_characters = ['FORREST', 'JENNY', 'DAN', 'BUBBA', 'MRS_GUMP']  \n",
    "popular_rows = []\n",
    "\n",
    "def character_priority(character):\n",
    "    '''Returns the priority index of a character in the main_characters list.'''\n",
    "    if character in main_characters:\n",
    "        return main_characters.index(character)\n",
    "    return float('inf')  # Characters not in the list get the lowest priority\n",
    "\n",
    "def has_main_character(group):\n",
    "    '''Returns the priority of the actor-recipient pair based on main characters.'''\n",
    "    actor = group['actor'].iloc[0]\n",
    "    recipient = group['recipient'].iloc[0]\n",
    "    \n",
    "    actor_priority = character_priority(actor)\n",
    "    recipient_priority = character_priority(recipient)\n",
    "    \n",
    "    return min(actor_priority, recipient_priority)  # Return the lower priority value (higher priority)\n",
    "    \n",
    "\n",
    "def bodypart_occurrences(df, col, num=15):\n",
    "    '''returns top num occurring body parts'''\n",
    "    bodyparts = dict()\n",
    "    for _, row in df.iterrows():\n",
    "        if not pd.isna(row[col]):\n",
    "            parts = row[col].split()\n",
    "            for part in parts:\n",
    "                bodyparts[part] = bodyparts.get(part, 0) + 1\n",
    "\n",
    "    return ' '.join(list(dict(sorted(bodyparts.items(), key=lambda item: item[1], reverse=True)).keys())[:num])\n",
    "\n",
    "\n",
    "def valence_avg(df, col):\n",
    "    '''Determine average valence'''\n",
    "    scale = {\n",
    "        'STRONG_NEGATIVE': 0,\n",
    "        'NEGATIVE': 1,\n",
    "        'POSITIVE': 2,\n",
    "        'STRONG_POSITIVE': 3,\n",
    "    }\n",
    "    sum = 0\n",
    "    count = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        if not pd.isna(row[col]):\n",
    "            sum += scale[row[col]]\n",
    "            count += 1\n",
    "             \n",
    "    return list(scale.keys())[round(sum / count)] if count != 0 else None\n",
    "\n",
    "\n",
    "def get_max_df(duplicates, ts_rows):\n",
    "    '''Determine the most popular actor-recipient pair, with main character prioritization.'''\n",
    "    \n",
    "    if duplicates:\n",
    "        # sort duplicates by priority of main characters\n",
    "        sorted_duplicates = sorted(duplicates, key=lambda x: min(character_priority(x[1]['actor'].iloc[0]), character_priority(x[1]['recipient'].iloc[0])))\n",
    "        \n",
    "        max_df = max(sorted_duplicates, key=lambda x: len(x[1]))[1]\n",
    "\n",
    "        # If max label is 'NONE', prioritize annotations including main characters.\n",
    "        if max_df['label'].iloc[0] == 'NONE':\n",
    "            main_character_rows = ts_rows[ts_rows['actor'].isin(main_characters) | ts_rows['recipient'].isin(main_characters)]\n",
    "            if not main_character_rows.empty:\n",
    "                duplicates = list(main_character_rows.groupby(['actor', 'recipient'], dropna=False))\n",
    "                sorted_duplicates = sorted(duplicates, key=lambda x: min(character_priority(x[1]['actor'].iloc[0]), character_priority(x[1]['recipient'].iloc[0])))\n",
    "                max_df = max(sorted_duplicates, key=lambda x: len(x[1]))[1]\n",
    "                \n",
    "        return max_df\n",
    "    return None\n",
    "\n",
    "\n",
    "# take popular vote, if there is a tie or NONE, give priority to main characters\n",
    "for ts in timesteps:\n",
    "    ts_rows = combined_df[combined_df['timestep'] == ts]\n",
    "    duplicates = list(ts_rows.groupby(['actor', 'recipient'], dropna=False))\n",
    "\n",
    "    # Get the max_df based on actor-recipient pair, with main character priority\n",
    "    max_df = get_max_df(duplicates, ts_rows)\n",
    "\n",
    "    if max_df is not None:\n",
    "        \n",
    "        # get top 3 body parts for actor and recipient\n",
    "        bodypart_actor = bodypart_occurrences(max_df, 'bodypart_actor', 3)\n",
    "        bodypart_recipient = bodypart_occurrences(max_df, 'bodypart_recipient', 3)\n",
    "\n",
    "        # take average of valences\n",
    "        valence_actor = valence_avg(max_df, 'valence_actor')\n",
    "        valence_recipient = valence_avg(max_df, 'valence_recipient')\n",
    "        \n",
    "        # all other columns take mode\n",
    "        popular_rows.append({\n",
    "            'timestep': ts,\n",
    "            'actor': max_df['actor'].iloc[0],\n",
    "            'recipient': max_df['recipient'].iloc[0],\n",
    "            'bodypart_actor': bodypart_actor,\n",
    "            'bodypart_recipient': bodypart_recipient,\n",
    "            'label': max_df['label'].mode().iloc[0] if not max_df['label'].mode().empty else None,\n",
    "            'intensity_of_body_contact': max_df['intensity_of_body_contact'].mode().iloc[0] if not max_df['intensity_of_body_contact'].mode().empty else None,\n",
    "            'valence_actor': valence_actor,\n",
    "            'valence_recipient': valence_avg(max_df, 'valence_recipient'),\n",
    "            'intention': max_df['intention'].mode().iloc[0] if not max_df['intention'].mode().empty else None,\n",
    "            'audio_information': max_df['audio_information'].mode().iloc[0] if not max_df['audio_information'].mode().empty else None\n",
    "        })\n",
    "    else:\n",
    "        popular_rows.append({\n",
    "            'timestep': ts,\n",
    "            'actor': None,\n",
    "            'recipient': None,\n",
    "            'bodypart_actor': None,\n",
    "            'bodypart_recipient': None,\n",
    "            'label': 'NONE',\n",
    "            'intensity_of_body_contact': None,\n",
    "            'valence_actor': None,\n",
    "            'valence_recipient': None,\n",
    "            'intention': None,\n",
    "            'audio_information': None\n",
    "        })\n",
    "\n",
    "    \n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "popular_df = pd.DataFrame(popular_rows)\n",
    "\n",
    "# Save to TSV file\n",
    "output_path = '/Users/lucaschoi/Documents/GitHub/DeepEmotion/data/touch/obs_pop_vote.tsv'\n",
    "popular_df.to_csv(output_path, index=False, sep='\\t')\n",
    "\n",
    "print(f'Saved popular vote results to {output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
